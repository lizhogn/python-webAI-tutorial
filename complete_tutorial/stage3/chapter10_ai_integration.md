# ç¬¬10ç« ï¼šAIæ¨¡å‹é›†æˆ

## ğŸ“š å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œä½ å°†æŒæ¡ï¼š
- AIæ¨¡å‹åœ¨Webåº”ç”¨ä¸­çš„é›†æˆæ–¹æ³•
- æ¨¡å‹åºåˆ—åŒ–å’ŒåŠ è½½æŠ€æœ¯
- å®æ—¶é¢„æµ‹å’Œæ‰¹å¤„ç†å®ç°
- æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å’ŒA/Bæµ‹è¯•
- æ€§èƒ½ä¼˜åŒ–å’Œç¼“å­˜ç­–ç•¥

## ğŸ¤– AIæ¨¡å‹é›†æˆæ¦‚è¿°

### 10.1 ä¸ºä»€ä¹ˆéœ€è¦AIæ¨¡å‹é›†æˆï¼Ÿ

AIæ¨¡å‹é›†æˆæ˜¯å°†è®­ç»ƒå¥½çš„æœºå™¨å­¦ä¹ æ¨¡å‹éƒ¨ç½²åˆ°Webåº”ç”¨ä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿï¼š
- **å®æ—¶é¢„æµ‹**ï¼šç”¨æˆ·è¾“å…¥æ•°æ®ï¼Œç«‹å³è·å¾—AIé¢„æµ‹ç»“æœ
- **æ‰¹é‡å¤„ç†**ï¼šå¤„ç†å¤§é‡æ•°æ®ï¼Œæé«˜æ•ˆç‡
- **æœåŠ¡åŒ–**ï¼šå°†AIèƒ½åŠ›ä½œä¸ºAPIæœåŠ¡æä¾›ç»™å…¶ä»–åº”ç”¨
- **ç”¨æˆ·ä½“éªŒ**ï¼šåœ¨Webç•Œé¢ä¸­ç›´æ¥ä½¿ç”¨AIåŠŸèƒ½

### 10.2 é›†æˆæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTPè¯·æ±‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   å‰ç«¯ç•Œé¢  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚   Web API   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚  AIæ¨¡å‹æœåŠ¡ â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚   ç¼“å­˜å±‚    â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ æ¨¡å‹åºåˆ—åŒ–å’ŒåŠ è½½

### 10.3 æ¨¡å‹åºåˆ—åŒ–æ–¹æ³•

#### ä½¿ç”¨pickle

```python
import pickle
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer

# è®­ç»ƒæ¨¡å‹ï¼ˆç¤ºä¾‹ï¼‰
vectorizer = TfidfVectorizer()
classifier = RandomForestClassifier()

# å‡è®¾å·²ç»è®­ç»ƒå¥½æ¨¡å‹
# vectorizer.fit(texts)
# classifier.fit(X_train, y_train)

# ä¿å­˜æ¨¡å‹
def save_model_pickle(model, filename):
    """ä½¿ç”¨pickleä¿å­˜æ¨¡å‹"""
    with open(filename, 'wb') as f:
        pickle.dump(model, f)

# åŠ è½½æ¨¡å‹
def load_model_pickle(filename):
    """ä½¿ç”¨pickleåŠ è½½æ¨¡å‹"""
    with open(filename, 'rb') as f:
        return pickle.load(f)

# ä¿å­˜æ¨¡å‹
save_model_pickle(vectorizer, 'vectorizer.pkl')
save_model_pickle(classifier, 'classifier.pkl')
```

#### ä½¿ç”¨joblibï¼ˆæ¨èï¼‰

```python
import joblib

# ä¿å­˜æ¨¡å‹
def save_model_joblib(model, filename):
    """ä½¿ç”¨joblibä¿å­˜æ¨¡å‹"""
    joblib.dump(model, filename)

# åŠ è½½æ¨¡å‹
def load_model_joblib(filename):
    """ä½¿ç”¨joblibåŠ è½½æ¨¡å‹"""
    return joblib.load(filename)

# ä¿å­˜æ¨¡å‹
save_model_joblib(vectorizer, 'vectorizer.joblib')
save_model_joblib(classifier, 'classifier.joblib')
```

### 10.4 æ¨¡å‹åŠ è½½å™¨ç±»

```python
import joblib
import os
from typing import Any, Dict, Optional
import logging

class ModelLoader:
    """æ¨¡å‹åŠ è½½å™¨ç±»"""
    
    def __init__(self, model_dir: str = "models"):
        self.model_dir = model_dir
        self.models: Dict[str, Any] = {}
        self.logger = logging.getLogger(__name__)
    
    def load_model(self, model_name: str, model_path: str) -> bool:
        """åŠ è½½å•ä¸ªæ¨¡å‹"""
        try:
            full_path = os.path.join(self.model_dir, model_path)
            if os.path.exists(full_path):
                self.models[model_name] = joblib.load(full_path)
                self.logger.info(f"æ¨¡å‹ {model_name} åŠ è½½æˆåŠŸ")
                return True
            else:
                self.logger.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
                return False
        except Exception as e:
            self.logger.error(f"åŠ è½½æ¨¡å‹ {model_name} å¤±è´¥: {str(e)}")
            return False
    
    def get_model(self, model_name: str) -> Optional[Any]:
        """è·å–æ¨¡å‹"""
        return self.models.get(model_name)
    
    def load_all_models(self) -> bool:
        """åŠ è½½æ‰€æœ‰æ¨¡å‹"""
        models_to_load = {
            'vectorizer': 'vectorizer.joblib',
            'classifier': 'classifier.joblib'
        }
        
        success = True
        for model_name, model_path in models_to_load.items():
            if not self.load_model(model_name, model_path):
                success = False
        
        return success
    
    def reload_model(self, model_name: str, model_path: str) -> bool:
        """é‡æ–°åŠ è½½æ¨¡å‹ï¼ˆç”¨äºæ¨¡å‹æ›´æ–°ï¼‰"""
        return self.load_model(model_name, model_path)

# ä½¿ç”¨ç¤ºä¾‹
model_loader = ModelLoader()
if model_loader.load_all_models():
    print("æ‰€æœ‰æ¨¡å‹åŠ è½½æˆåŠŸ")
else:
    print("éƒ¨åˆ†æ¨¡å‹åŠ è½½å¤±è´¥")
```

## ğŸš€ FastAPIä¸­çš„AIæ¨¡å‹é›†æˆ

### 10.5 åŸºæœ¬AIæœåŠ¡

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional
import numpy as np
from model_loader import ModelLoader

app = FastAPI(title="AIé¢„æµ‹æœåŠ¡")

# åˆå§‹åŒ–æ¨¡å‹åŠ è½½å™¨
model_loader = ModelLoader()
model_loader.load_all_models()

# æ•°æ®æ¨¡å‹
class PredictionRequest(BaseModel):
    text: str

class PredictionResponse(BaseModel):
    prediction: str
    confidence: float
    model_version: str

class BatchPredictionRequest(BaseModel):
    texts: List[str]

class BatchPredictionResponse(BaseModel):
    predictions: List[str]
    confidences: List[float]
    model_version: str

# é¢„æµ‹å‡½æ•°
def predict_sentiment(text: str) -> tuple:
    """é¢„æµ‹æ–‡æœ¬æƒ…æ„Ÿ"""
    try:
        vectorizer = model_loader.get_model('vectorizer')
        classifier = model_loader.get_model('classifier')
        
        if vectorizer is None or classifier is None:
            raise ValueError("æ¨¡å‹æœªåŠ è½½")
        
        # ç‰¹å¾æå–
        features = vectorizer.transform([text])
        
        # é¢„æµ‹
        prediction = classifier.predict(features)[0]
        confidence = np.max(classifier.predict_proba(features))
        
        return prediction, confidence
    except Exception as e:
        raise ValueError(f"é¢„æµ‹å¤±è´¥: {str(e)}")

# APIç«¯ç‚¹
@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    """å•æ¡æ–‡æœ¬é¢„æµ‹"""
    try:
        prediction, confidence = predict_sentiment(request.text)
        
        return PredictionResponse(
            prediction=prediction,
            confidence=float(confidence),
            model_version="1.0.0"
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æœåŠ¡å™¨é”™è¯¯: {str(e)}")

@app.post("/predict/batch", response_model=BatchPredictionResponse)
async def predict_batch(request: BatchPredictionRequest):
    """æ‰¹é‡é¢„æµ‹"""
    try:
        vectorizer = model_loader.get_model('vectorizer')
        classifier = model_loader.get_model('classifier')
        
        if vectorizer is None or classifier is None:
            raise HTTPException(status_code=500, detail="æ¨¡å‹æœªåŠ è½½")
        
        # æ‰¹é‡ç‰¹å¾æå–
        features = vectorizer.transform(request.texts)
        
        # æ‰¹é‡é¢„æµ‹
        predictions = classifier.predict(features)
        confidences = np.max(classifier.predict_proba(features), axis=1)
        
        return BatchPredictionResponse(
            predictions=predictions.tolist(),
            confidences=confidences.tolist(),
            model_version="1.0.0"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡é¢„æµ‹å¤±è´¥: {str(e)}")

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    models_loaded = all([
        model_loader.get_model('vectorizer') is not None,
        model_loader.get_model('classifier') is not None
    ])
    
    return {
        "status": "healthy" if models_loaded else "unhealthy",
        "models_loaded": models_loaded,
        "model_count": len(model_loader.models)
    }
```

## ğŸ“ æœ¬ç« å°ç»“

### é‡ç‚¹æ¦‚å¿µ
- âœ… AIæ¨¡å‹åœ¨Webåº”ç”¨ä¸­çš„é›†æˆæ–¹æ³•
- âœ… æ¨¡å‹åºåˆ—åŒ–å’ŒåŠ è½½æŠ€æœ¯
- âœ… å®æ—¶é¢„æµ‹å’Œæ‰¹å¤„ç†å®ç°
- âœ… æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å’ŒA/Bæµ‹è¯•
- âœ… æ€§èƒ½ä¼˜åŒ–å’Œç¼“å­˜ç­–ç•¥

### å…³é”®æŠ€èƒ½
- âœ… ä½¿ç”¨joblibåºåˆ—åŒ–å’ŒåŠ è½½æ¨¡å‹
- âœ… åœ¨FastAPIä¸­é›†æˆAIæ¨¡å‹
- âœ… å®ç°æ¨¡å‹ç¼“å­˜å’Œå¼‚æ­¥å¤„ç†
- âœ… è®¾è®¡A/Bæµ‹è¯•æ¡†æ¶
- âœ… æ„å»ºå®Œæ•´çš„AI Webåº”ç”¨

## ğŸ”— æ‰©å±•é˜…è¯»

- [scikit-learnæ¨¡å‹æŒä¹…åŒ–](https://scikit-learn.org/stable/modules/model_persistence.html)
- [FastAPIæœ€ä½³å®è·µ](https://fastapi.tiangolo.com/tutorial/)
- [Redisç¼“å­˜ç­–ç•¥](https://redis.io/topics/caching)
- [Celeryå¼‚æ­¥ä»»åŠ¡](https://docs.celeryproject.org/)

## â“ å¸¸è§é—®é¢˜

**Q: å¦‚ä½•é€‰æ‹©æ¨¡å‹åºåˆ—åŒ–æ–¹æ³•ï¼Ÿ**
A: joblibé€šå¸¸æ¯”pickleæ›´å®‰å…¨ï¼Œæ”¯æŒå¤§æ–‡ä»¶ï¼Œæ¨èä½¿ç”¨joblibã€‚

**Q: æ¨¡å‹æ–‡ä»¶å¾ˆå¤§æ€ä¹ˆåŠï¼Ÿ**
A: è€ƒè™‘æ¨¡å‹å‹ç¼©ã€é‡åŒ–ã€ä½¿ç”¨æ›´è½»é‡çš„æ¨¡å‹ï¼Œæˆ–è€…ä½¿ç”¨æ¨¡å‹æœåŠ¡åŒ–ã€‚

**Q: å¦‚ä½•ç›‘æ§æ¨¡å‹æ€§èƒ½ï¼Ÿ**
A: è®°å½•é¢„æµ‹ç»“æœã€ç”¨æˆ·åé¦ˆã€æ¨¡å‹æŒ‡æ ‡ï¼Œå®šæœŸè¯„ä¼°æ¨¡å‹æ•ˆæœã€‚

---

**ä¸‹ä¸€ç« ï¼šå¼‚æ­¥å¤„ç†** â†’ [ç¬¬11ç« ï¼šå¼‚æ­¥å¤„ç†](./chapter11_async_processing.md) 