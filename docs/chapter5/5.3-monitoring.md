# 5.3 监控与日志

## 概述

监控与日志系统是生产环境运维的核心组件，它帮助我们了解应用性能、系统状态、用户行为等信息，为问题诊断和性能优化提供数据支持。

## 学习目标

- 理解监控系统的重要性和组成部分
- 掌握日志收集和分析方法
- 学会配置告警和通知机制
- 了解性能监控和可视化

## 监控系统架构

### 监控层次

1. **基础设施监控**：CPU、内存、磁盘、网络
2. **应用监控**：响应时间、错误率、吞吐量
3. **业务监控**：用户活跃度、转化率、收入
4. **用户体验监控**：页面加载时间、可用性

### 监控工具栈

```yaml
# 监控工具选择
基础设施监控:
  - Prometheus + Grafana
  - Zabbix
  - Nagios

应用性能监控:
  - APM (Application Performance Monitoring)
  - Jaeger (分布式追踪)
  - Zipkin

日志管理:
  - ELK Stack (Elasticsearch + Logstash + Kibana)
  - Fluentd
  - Graylog
```

## Prometheus 监控系统

### 基本概念

Prometheus 是一个开源的监控和告警系统，具有以下特点：

- **时间序列数据库**：存储监控指标
- **拉取模式**：主动从目标获取指标
- **强大的查询语言**：PromQL
- **告警管理**：AlertManager

### 安装和配置

```yaml
# docker-compose.yml
version: '3.8'
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin

volumes:
  prometheus_data:
  grafana_data:
```

### Prometheus 配置

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  - job_name: 'python-app'
    static_configs:
      - targets: ['app:8000']
    metrics_path: '/metrics'
    scrape_interval: 10s
```

## 应用监控集成

### Python 应用监控

```python
# app.py
from flask import Flask, request, jsonify
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
import time

app = Flask(__name__)

# 定义监控指标
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint', 'status'])
REQUEST_LATENCY = Histogram('http_request_duration_seconds', 'HTTP request latency')

@app.before_request
def before_request():
    request.start_time = time.time()

@app.after_request
def after_request(response):
    # 记录请求计数
    REQUEST_COUNT.labels(
        method=request.method,
        endpoint=request.endpoint,
        status=response.status_code
    ).inc()
    
    # 记录请求延迟
    REQUEST_LATENCY.observe(time.time() - request.start_time)
    
    return response

@app.route('/metrics')
def metrics():
    return generate_latest(), 200, {'Content-Type': CONTENT_TYPE_LATEST}

@app.route('/api/data')
def get_data():
    return jsonify({'message': 'Hello, World!'})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8000)
```

### 自定义指标

```python
# custom_metrics.py
from prometheus_client import Gauge, Counter, Histogram
import psutil
import threading
import time

# 系统资源指标
CPU_USAGE = Gauge('cpu_usage_percent', 'CPU usage percentage')
MEMORY_USAGE = Gauge('memory_usage_percent', 'Memory usage percentage')
DISK_USAGE = Gauge('disk_usage_percent', 'Disk usage percentage')

# 业务指标
ACTIVE_USERS = Gauge('active_users', 'Number of active users')
TOTAL_ORDERS = Counter('total_orders', 'Total number of orders')
ORDER_VALUE = Histogram('order_value', 'Order value distribution')

def collect_system_metrics():
    """收集系统指标"""
    while True:
        CPU_USAGE.set(psutil.cpu_percent())
        MEMORY_USAGE.set(psutil.virtual_memory().percent)
        DISK_USAGE.set(psutil.disk_usage('/').percent)
        time.sleep(15)

# 启动指标收集线程
threading.Thread(target=collect_system_metrics, daemon=True).start()
```

## 日志管理

### 日志格式标准

```python
# logging_config.py
import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_entry = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno
        }
        
        # 添加异常信息
        if record.exc_info:
            log_entry['exception'] = self.formatException(record.exc_info)
        
        # 添加额外字段
        if hasattr(record, 'user_id'):
            log_entry['user_id'] = record.user_id
        if hasattr(record, 'request_id'):
            log_entry['request_id'] = record.request_id
            
        return json.dumps(log_entry)

# 配置日志
def setup_logging():
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # 控制台处理器
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(JSONFormatter())
    logger.addHandler(console_handler)
    
    # 文件处理器
    file_handler = logging.FileHandler('app.log')
    file_handler.setFormatter(JSONFormatter())
    logger.addHandler(file_handler)
    
    return logger
```

### 结构化日志

```python
# structured_logging.py
import logging
import uuid
from functools import wraps

logger = logging.getLogger(__name__)

def log_request(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        request_id = str(uuid.uuid4())
        
        # 记录请求开始
        logger.info('Request started', extra={
            'request_id': request_id,
            'function': f.__name__,
            'args': args,
            'kwargs': kwargs
        })
        
        try:
            result = f(*args, **kwargs)
            
            # 记录请求成功
            logger.info('Request completed', extra={
                'request_id': request_id,
                'status': 'success',
                'result': result
            })
            
            return result
            
        except Exception as e:
            # 记录请求失败
            logger.error('Request failed', extra={
                'request_id': request_id,
                'status': 'error',
                'error': str(e)
            })
            raise
    
    return decorated_function

@log_request
def process_data(data):
    # 处理逻辑
    return {'processed': True, 'data': data}
```

## ELK Stack 日志分析

### Elasticsearch 配置

```yaml
# elasticsearch.yml
cluster.name: my-cluster
node.name: node-1
network.host: 0.0.0.0
http.port: 9200
discovery.type: single-node

# 内存配置
bootstrap.memory_lock: true
indices.memory.index_buffer_size: 30%
```

### Logstash 配置

```ruby
# logstash.conf
input {
  file {
    path => "/var/log/app/*.log"
    type => "application"
    start_position => "beginning"
  }
  
  beats {
    port => 5044
    type => "beats"
  }
}

filter {
  if [type] == "application" {
    json {
      source => "message"
    }
    
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
    }
    
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "app-logs-%{+YYYY.MM.dd}"
  }
  
  stdout {
    codec => rubydebug
  }
}
```

### Kibana 可视化

```json
// 创建索引模式
{
  "index_patterns": ["app-logs-*"],
  "template": {
    "settings": {
      "number_of_shards": 1,
      "number_of_replicas": 0
    },
    "mappings": {
      "properties": {
        "timestamp": {"type": "date"},
        "level": {"type": "keyword"},
        "message": {"type": "text"},
        "user_id": {"type": "keyword"},
        "request_id": {"type": "keyword"}
      }
    }
  }
}
```

## 告警系统

### Prometheus 告警规则

```yaml
# alert_rules.yml
groups:
  - name: app_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second"

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time"
          description: "95th percentile response time is {{ $value }} seconds"

      - alert: HighCPUUsage
        expr: cpu_usage_percent > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is {{ $value }}%"

      - alert: HighMemoryUsage
        expr: memory_usage_percent > 85
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value }}%"
```

### AlertManager 配置

```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alertmanager@example.com'
  smtp_auth_username: 'your-email@gmail.com'
  smtp_auth_password: 'your-password'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

receivers:
  - name: 'web.hook'
    webhook_configs:
      - url: 'http://127.0.0.1:5001/'

  - name: 'email'
    email_configs:
      - to: 'admin@example.com'
        send_resolved: true

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'dev', 'instance']
```

## 性能监控

### APM 集成

```python
# apm_integration.py
from elasticapm import Client, instrument
from elasticapm.contrib.flask import ElasticAPM
from flask import Flask

app = Flask(__name__)

# 配置 APM
apm = Client(
    service_name='my-python-app',
    server_url='http://apm-server:8200',
    environment='production'
)

# 集成到 Flask
ElasticAPM(app, client=apm)

# 自定义追踪
@app.route('/api/process')
def process_data():
    # 开始自定义事务
    with apm.capture_span('data_processing'):
        # 处理逻辑
        result = complex_processing()
        
        # 记录自定义指标
        apm.metrics.counter('custom_metric', 1)
        
        return result

# 性能追踪装饰器
@instrument()
def complex_processing():
    # 复杂处理逻辑
    pass
```

### 分布式追踪

```python
# distributed_tracing.py
import opentracing
from jaeger_client import Config
from flask import Flask, request

app = Flask(__name__)

# 配置 Jaeger
def init_tracer():
    config = Config(
        config={
            'sampler': {'type': 'const', 'param': 1},
            'logging': True,
            'local_agent': {'reporting_host': 'jaeger-agent'}
        },
        service_name='my-python-app'
    )
    return config.initialize_tracer()

tracer = init_tracer()

@app.route('/api/data')
def get_data():
    # 从请求头获取追踪上下文
    span_ctx = tracer.extract(opentracing.Format.HTTP_HEADERS, request.headers)
    
    with tracer.start_span('get_data', child_of=span_ctx) as span:
        span.set_tag('http.method', request.method)
        span.set_tag('http.url', request.url)
        
        # 调用其他服务
        with tracer.start_span('call_external_service', child_of=span) as child_span:
            result = call_external_service()
            child_span.set_tag('service.name', 'external-service')
            
        return result
```

## 监控仪表板

### Grafana 仪表板

```json
{
  "dashboard": {
    "title": "Application Monitoring",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m])",
            "legendFormat": "5xx errors"
          }
        ]
      },
      {
        "title": "System Resources",
        "type": "graph",
        "targets": [
          {
            "expr": "cpu_usage_percent",
            "legendFormat": "CPU Usage"
          },
          {
            "expr": "memory_usage_percent",
            "legendFormat": "Memory Usage"
          }
        ]
      }
    ]
  }
}
```

## 实践项目

### 项目：完整的监控系统

创建一个完整的监控系统，包含：

1. **Prometheus 指标收集**：系统和应用指标
2. **Grafana 可视化**：创建监控仪表板
3. **ELK 日志分析**：日志收集和分析
4. **告警系统**：配置告警规则和通知
5. **APM 性能监控**：应用性能追踪

```yaml
# docker-compose.monitoring.yml
version: '3.8'
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - ./alert_rules.yml:/etc/prometheus/alert_rules.yml
      - prometheus_data:/prometheus

  alertmanager:
    image: prom/alertmanager:latest
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:7.17.0
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    ports:
      - "5044:5044"

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200

  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - "16686:16686"
      - "14268:14268"

volumes:
  prometheus_data:
  grafana_data:
  elasticsearch_data:
```

## 学习资源

- [Prometheus 官方文档](https://prometheus.io/docs/)
- [Grafana 文档](https://grafana.com/docs/)
- [ELK Stack 指南](https://www.elastic.co/guide/index.html)
- [Jaeger 分布式追踪](https://www.jaegertracing.io/docs/)

## 知识检查

1. **监控系统的组成部分有哪些？**
   - 指标收集、存储、可视化、告警

2. **Prometheus 的特点是什么？**
   - 时间序列数据库、拉取模式、PromQL 查询语言

3. **如何配置应用监控？**
   - 集成 Prometheus 客户端、定义自定义指标

4. **ELK Stack 的作用是什么？**
   - 日志收集、存储、搜索、可视化

5. **告警系统如何配置？**
   - 定义告警规则、配置通知渠道

## 下一步

在下一章节中，我们将学习安全配置，了解如何保护应用和系统安全。 